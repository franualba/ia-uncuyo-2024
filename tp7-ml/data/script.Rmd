```{r}
# Read the CSV file
data <- read.csv("./arbolado-mza-dataset.csv")

# Set a seed for reproducibility
set.seed(123)

# Create an index for the 20% validation set
validation_index <- sample(1:nrow(data), size = 0.2 * nrow(data))

# Split the data
validation_data <- data[validation_index, ]
training_data <- data[-validation_index, ]

# Write the split datasets to new CSV files
write.csv(validation_data, "arbolado-mendoza-dataset-validation.csv", row.names = FALSE)
write.csv(training_data, "arbolado-mendoza-dataset-train.csv", row.names = FALSE)
```


```{r}
library(dplyr)

data_train <- read.csv("./arbolado-mendoza-dataset-train.csv")
data_train <- data_train %>% mutate(inclinacion_peligrosa=ifelse(inclinacion_peligrosa=='1','si','no'))
data_train$inclinacion_peligrosa <- as.factor(data_train$inclinacion_peligrosa)
data_train

```

```{r}
data_train %>%  group_by(inclinacion_peligrosa) %>% summarise(total=n())

```

```{r}
library(ggplot2)

data_train_seccion_inclinacion <- data_train %>% group_by(seccion,inclinacion_peligrosa) %>% summarise(total=n())
data_train_seccion_inclinacion

ggplot(data_train) + geom_bar(aes(x=as.factor(inclinacion_peligrosa),fill=as.factor(inclinacion_peligrosa))) + theme_bw() + facet_wrap(~seccion)

```

```{r}
library(ggplot2)

data_train_especie_inclinacion <- data_train %>%  group_by(especie,inclinacion_peligrosa) %>% summarise(total=n())
data_train_especie_inclinacion

ggplot(data_train) + geom_bar(aes(x=as.factor(inclinacion_peligrosa),fill=as.factor(inclinacion_peligrosa))) + theme_bw() + facet_wrap(~especie)

```

```{r}
library(ggplot2)

ggplot(data_train, aes(x = circ_tronco_cm)) + 
  geom_histogram(breaks = seq(floor(min(data_train$circ_tronco_cm)), floor(max(data_train$circ_tronco_cm)), by = 20)) + 
  labs(title = "Histograma de Frecuencia para todos los árboles", x = "circ_tronco_cm", y = "Frequency") +
  scale_x_continuous(breaks = seq(floor(min(data_train$circ_tronco_cm)), floor(max(data_train$circ_tronco_cm)), by = 20))

```
```{r}
library(ggplot2)

ggplot(data_train %>% filter(inclinacion_peligrosa == "si"), aes(x = circ_tronco_cm)) + 
  geom_histogram(breaks = seq(floor(min(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "si"])), floor(max(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "si"])), by = 20)) + 
  labs(title = "Histograma para árboles con inclinación peligrosa", x = "circ_tronco_cm", y = "Frequency") +
  scale_x_continuous(breaks = seq(floor(min(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "si"])), floor(max(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "si"])), by = 20))

ggplot(data_train %>% filter(inclinacion_peligrosa == "no"), aes(x = circ_tronco_cm)) + 
  geom_histogram(breaks = seq(floor(min(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "no"])), floor(max(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "no"])), by = 20)) + 
  labs(title = "Histograma para árboles sin inclinación peligrosa", x = "circ_tronco_cm", y = "Frequency") +
  scale_x_continuous(breaks = seq(floor(min(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "no"])), floor(max(data_train$circ_tronco_cm[data_train$inclinacion_peligrosa == "no"])), by = 20))

```


```{r}
# Step 1: Determine the quartiles of circ_tronco_cm
quartiles <- quantile(data_train$circ_tronco_cm, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)

# Step 2: Create the new categorical variable
data_train$circ_tronco_cm_cat <- cut(data_train$circ_tronco_cm, 
                                 breaks = c(-Inf, quartiles, Inf),
                                 labels = c("bajo", "medio", "alto", "muy alto"),
                                 include.lowest = TRUE)

# Step 3: Save the updated data frame as a CSV file
write.csv(data_train, "arbolado-mendoza-dataset-circ_tronco_cm-train.csv", row.names = FALSE)

# Print the first few rows to verify the new column
# print(head(data_train[c("circ_tronco_cm", "circ_tronco_cm_cat")]))

# Print a summary of the new categorical variable
# print(table(data_train$circ_tronco_cm_cat))
```

```{r}

### EJERCICIO 4

# a) 

add_random_prediction <- function(df) {
  df$prediction_prob <- runif(nrow(df))
  return(df)
}

# b)

random_classifier <- function(df) {
  df$prediction_class_random <- ifelse(df$prediction_prob > 0.5, 1, 0)
  return(df)
}

# c)

library(readr)
options(readr.show_col_types = FALSE)
library(dplyr)

# Cargar el archivo
df <- read_csv("./arbolado-mendoza-dataset-validation.csv")

# Aplicar las funciones
df <- df %>% add_random_prediction() %>% random_classifier()

# d)

# Cálculo de la matriz de confusión
confusion_matrix_random <- matrix(c(
  sum(df$inclinacion_peligrosa == 1 & df$prediction_class_random == 1),  # TP
  sum(df$inclinacion_peligrosa == 1 & df$prediction_class_random == 0),  # FN
  sum(df$inclinacion_peligrosa == 0 & df$prediction_class_random == 1),  # FP
  sum(df$inclinacion_peligrosa == 0 & df$prediction_class_random == 0)   # TN
), nrow = 2, byrow = TRUE)

rownames(confusion_matrix_random) <- c("Actual 1", "Actual 0")
colnames(confusion_matrix_random) <- c("Predicted 1", "Predicted 0")

print(confusion_matrix_random)

```

```{r}

### EJERCICIO 5

# a)

biggerclass_classifier <- function(df) {
  # Determinar la clase mayoritaria
  majority_class <- as.numeric(names(which.max(table(df$inclinacion_peligrosa))))
  
  # Asignar la clase mayoritaria a todos los registros
  df$prediction_class_majority <- majority_class
  
  return(df)
}

# b)

library(readr)
options(readr.show_col_types = FALSE)
library(dplyr)

# Cargar el archivo
df <- read_csv("./arbolado-mendoza-dataset-validation.csv")

# Aplicar la función biggerclass_classifier
df <- biggerclass_classifier(df)

# Cálculo de la matriz de confusión
confusion_matrix_biggerclass <- matrix(c(
  sum(df$inclinacion_peligrosa == 1 & df$prediction_class_majority == 1),  # TP
  sum(df$inclinacion_peligrosa == 1 & df$prediction_class_majority == 0),  # FN
  sum(df$inclinacion_peligrosa == 0 & df$prediction_class_majority == 1),  # FP
  sum(df$inclinacion_peligrosa == 0 & df$prediction_class_majority == 0)   # TN
), nrow = 2, byrow = TRUE)

rownames(confusion_matrix_biggerclass) <- c("Actual 1", "Actual 0")
colnames(confusion_matrix_biggerclass) <- c("Predicted 1", "Predicted 0")

print(confusion_matrix_biggerclass)

print(paste("Clase mayoritaria:", unique(df$prediction_class_majority)))

```

```{r}

### EJERCICIO 6

calculate_accuracy <- function(confusion_matrix) {
  TP <- confusion_matrix[1,1]
  TN <- confusion_matrix[2,2]
  total <- sum(confusion_matrix)
  return((TP + TN) / total)
}

calculate_precision <- function(confusion_matrix) {
  TP <- confusion_matrix[1,1]
  FP <- confusion_matrix[2,1]
  return(TP / (TP + FP))
}

calculate_sensitivity <- function(confusion_matrix) {
  TP <- confusion_matrix[1,1]
  FN <- confusion_matrix[1,2]
  return(TP / (TP + FN))
}

calculate_specificity <- function(confusion_matrix) {
  TN <- confusion_matrix[2,2]
  FP <- confusion_matrix[2,1]
  return(TN / (TN + FP))
}

writeLines("Random Classifier\n")

print(confusion_matrix_random)

writeLines("\n")

accuracy_random <- calculate_accuracy(confusion_matrix_random)
precision_random <- calculate_precision(confusion_matrix_random)
sensitivity_random <- calculate_sensitivity(confusion_matrix_random)
specificity_random <- calculate_specificity(confusion_matrix_random)

print(paste("Accuracy:", round(accuracy_random, 4)))
print(paste("Precision:", round(precision_random, 4)))
print(paste("Sensitivity:", round(sensitivity_random, 4)))
print(paste("Specificity:", round(specificity_random, 4)))

writeLines("\n")

writeLines("Biggerclass Classifier\n")

print(confusion_matrix_biggerclass)

writeLines("\n")

accuracy_biggerclass <- calculate_accuracy(confusion_matrix_biggerclass)
precision_biggerclass <- calculate_precision(confusion_matrix_biggerclass)
sensitivity_biggerclass <- calculate_sensitivity(confusion_matrix_biggerclass)
specificity_biggerclass <- calculate_specificity(confusion_matrix_biggerclass)

print(paste("Accuracy:", round(accuracy_biggerclass, 4)))
print(paste("Precision:", round(precision_biggerclass, 4)))
print(paste("Sensitivity:", round(sensitivity_biggerclass, 4)))
print(paste("Specificity:", round(specificity_biggerclass, 4)))

```

```{r}

### EJERCICIO 7 

# a)

create_folds <- function(df, num_folds) {
  # Obtener el número total de filas en el dataframe
  n <- nrow(df)
  
  # Crear un vector de índices aleatorios
  indices <- sample(1:n)
  
  # Calcular el tamaño aproximado de cada fold
  fold_size <- ceiling(n / num_folds)
  
  # Crear la lista de folds
  folds <- list()
  for (i in 1:num_folds) {
    start_index <- (i - 1) * fold_size + 1
    end_index <- min(i * fold_size, n)
    folds[[paste0("Fold", i)]] <- indices[start_index:end_index]
  }
  
  return(folds)
}

# b)

library(rpart)
library(caret)

cross_validation <- function(df, num_folds) {
  folds <- create_folds(df, num_folds)
  
  metrics <- data.frame(Accuracy=numeric(num_folds),
                        Precision=numeric(num_folds),
                        Sensitivity=numeric(num_folds),
                        Specificity=numeric(num_folds))
  
  for (i in 1:num_folds) {
    # Separar datos de entrenamiento y prueba
    test_indices <- folds[[i]]
    train_indices <- unlist(folds[-i])
    
    train_data <- df[train_indices, ]
    test_data <- df[test_indices, ]
    
    # Entrenar el modelo
    model <- rpart(inclinacion_peligrosa ~ diametro_tronco + altura, data=train_data, method="class")
    
    # Hacer predicciones
    predictions <- predict(model, test_data, type="class")
    
    # Calcular matriz de confusión
    conf_matrix <- table(test_data$inclinacion_peligrosa, predictions)
    print(conf_matrix)
    
    # Calcular métricas
    metrics$Accuracy[i] <- calculate_accuracy(conf_matrix)
    metrics$Precision[i] <- calculate_precision(conf_matrix)
    metrics$Sensitivity[i] <- calculate_sensitivity(conf_matrix)
    metrics$Specificity[i] <- calculate_specificity(conf_matrix)
  }
  
  # Calcular media y desviación estándar
  results <- data.frame(
    Mean = colMeans(metrics),
    SD = apply(metrics, 2, sd)
  )
  
  return(results)
}

results <- cross_validation(df, 10)  # 10 fold cross validation

print(results)


```










































